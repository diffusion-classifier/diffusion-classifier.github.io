<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">

    <meta charset="utf-8">
    <meta property="og:title" content="Diffusion Classifier" />
    <meta property="og:description" content="Your Diffusion Model is Secretly a Zero-Shot Classifier" />
    <meta property="og:url" content="https://diffusion-classifier.github.io/" />
    <meta property="og:image" content="https://diffusion-classifier.github.io//static/images/preview.jpeg" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="628" />
    <meta name="description"
        content="Diffusion Classifier leverages pretrained diffusion models to perform zero-shot classification without additional training." />
    <meta name="keywords"
        content="diffusion models, generative models, zero-shot learning, supervised learning, classification, Bayes' theorem, evidence lower bound (ELBO), Monte Carlo estimation, computer vision, deep learning, robustness" />
    <meta name="viewport" content="initial-scale=1" />
    <!-- twitter -->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Diffusion Classifier" />
    <meta name="twitter:description"
        content="Diffusion Classifier leverages pretrained diffusion models to perform zero-shot classification without additional training." />
    <meta name="twitter:url" content="https://diffusion-classifier.github.io/" />
    <meta name="twitter:image" content="https://diffusion-classifier.github.io/static/images/preview.jpeg" />
    <meta name="twitter:site" content="@pathak2206" />
    <meta name="twitter:image" content="https://diffusion-classifier.github.io/static/images/preview.jpeg" />
    <meta name="twitter:image:src" content="https://diffusion-classifier.github.io/static/images/preview.jpeg" />
    <meta name="twitter:image_alt" content="Diffusion Classifier" />

    <title>Diffusion Classifier</title>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-RYWGEJGP6S"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-RYWGEJGP6S');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" href="https://use.typekit.net/iag3ven.css">

    <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism-coy.min.css"/> -->
    <link rel="stylesheet" href="./static/css/prism.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/prism.min.js">
    </script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.0.1/prism-bibtex.min.js">
    </script>

    <link rel="icon"
        href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ”Ž</text></svg>">


    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://d3js.org/d3.v3.min.js" charset="utf-8"></script>
    <script src="https://d3js.org/topojson.v1.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>

    <!-- mathjax -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>

<body>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <p style="padding: 20px;" />
                        <h1 class="title is-1 publication-title">
                            <span id="main-title">
                                Your Diffusion Model is Secretly a Zero-Shot Classifier
                            </span>
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <!-- TODO: FIX -->
                            <span class="author-block">
                                <a href="http://alexanderli.com/" target="_blank">Alexander C.
                                    Li</a>
                            </span>
                            &nbsp;
                            &nbsp;
                            <span class="author-block">
                                <a href="https://mihirp1998.github.io/" target="_blank">Mihir Prabhudesai</a>
                            </span>
                            &nbsp;
                            &nbsp;
                            <span class="author-block">
                                <a href="https://shivamduggal4.github.io/" target="_blank">Shivam Duggal</a>
                            </span>
                            &nbsp;
                            &nbsp;
                            <span class="author-block">
                                <a href="https://ellisbrown.github.io/" target="_blank">Ellis Brown</a>
                            </span>
                            &nbsp;
                            &nbsp;
                            <span class="author-block">
                                <a href="https://www.cs.cmu.edu/~dpathak/" target="_blank">Deepak Pathak</a>
                            </span>
                        </div>
                        <p style="padding: 0.25rem;" />
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">Carnegie Mellon University</span>
                            <!-- <br style="line-height: 2px" /> -->
                            <!-- <span class="author-block" style="font-size: 0.7em; font-style: italic;"><sup>*</sup>Equal
                                contribution</span> -->

                        </div>

                        <p style="padding: 20px;" />

                        <div class="buttons is-centered">
                            <button class="external-link button is-medium is-ghost publication-links is-rounded">
                                <a href="https://arxiv.org/abs/2303.16203" target="_blank"
                                    style="text-decoration:none;">
                                    <span class="icon is-small">
                                        <i class="ai ai-arxiv"></i>
                                    </span>
                                    <span>arXiv</span>
                                </a>
                            </button>
                            <button class="external-link button is-medium is-ghost publication-links is-rounded">
                                <a href="./static/docs/DiffusionClassifier.pdf" target="_blank">
                                    <span class="icon is-small">
                                        <i class="fas fa-file-pdf"></i>
                                    </span>
                                    <span>pdf</span>
                                </a>
                            </button>
                            <!-- <button class="external-link button is-medium is-ghost publication-links is-rounded">
                                <a href="https://youtu.be/1hYtGZ0CUSA" target="_blank">
                                    <span class="icon">
                                        <i class="fab fa-youtube"></i>
                                    </span><span>video</span>
                                </a>
                            </button> -->
                            <!-- <button class="external-link button is-medium is-ghost publication-links is-rounded">
                                <a href="./static/docs/InternetExplorer.pptx" target="_blank">
                                    <span class="icon is-small">
                                        <i class="fas fa-file-powerpoint"></i>
                                    </span>
                                    <span>slides</span>
                                </a>
                            </button> -->
                            <button class="external-link button is-medium is-ghost publication-links is-rounded">
                                <a href="https://github.com/diffusion-classifier/diffusion-classifier" target="_blank">
                                    <span class="icon is-small">
                                        <i class="fab fa-github"></i>
                                    </span>
                                    <span>code</span>
                                </a>
                            </button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- hack to pull the below up vertically -->
    <span style="display:block; margin-top:-1.75em;"/>

        <!-- Method Overview -->
    <section class="section" id="method-overview">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column" style="border-radius: 10px; background-color: rgb(245,245,245)">
                    <h2 class="title is-3">
                        <span class="method-name">"Diffusion Classifier"</span>
                    </h2>
                    <p style="padding: 10px;" />
                    <div id="method-overview-wrapper">
                        <img src="./static/images/arch_figure.jpg" alt="Diffusion Classifier method."
                            class="method-overview-full-img  method-overview" draggable="false" />
                    </div>
                            <p style="padding: 10px;" />
                        <div class="method-overview-text has-text-justified">
                            <p>
                                Given an input image  \(\mathbf x \) and text conditioning \(\mathbf c\),
                                <!-- (e.g., text for Stable Diffusion or class index for DiT), -->
                                we use a diffusion model to choose
                                the class that best fits this image.
                                Our approach, <span class="method-name">Diffusion Classifier</span>, is 
                                theoretically motivated through the variational view of
                                diffusion models and uses the ELBO to approximate
                                \(\log p_{\theta}(\mathbf x|\mathbf c).\)
                                Diffusion Classifier chooses the conditioning
                                \(\mathbf c\)
                                that best predicts the noise added to the input image. Diffusion Classifier can be used
                                to extract a
                                <i>zero-shot classifier from a text-to-image model</i> (like Stable Diffusion) and a
                                <i>standard classifier from a class-conditional model</i> (like DiT) without any
                                additional training.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!--/ Method Overview -->

    <!-- <p style="padding: 10px;" /> -->

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            The recent wave of large-scale text-to-image diffusion models has dramatically increased our
                            text-based image generation abilities. These models can generate realistic images for a
                            staggering variety of prompts and exhibit impressive compositional generalization abilities.
                            Almost all use cases thus far have solely focused on <i>sampling</i>; however, diffusion
                            models can also provide conditional density estimates, which are useful for tasks beyond
                            image generation.
                        </p>
                        <p>
                            In this paper, we show that the density estimates from large-scale text-to-image diffusion
                            models like Stable Diffusion can be leveraged to perform zero-shot classification
                            <em>without any additional
                                training</em>.
                            Our generative approach to classification, which we call <span class="method-name">Diffusion
                                Classifier</span>, attains strong results on a variety of benchmarks and outperforms
                            alternative methods of extracting knowledge from diffusion models.
                            We also find that our diffusion-based approach has stronger <i>multimodal</i> relational
                            reasoning abilities than competing contrastive approaches.
                        </p>
                        <p>
                            Finally, we use Diffusion Classifier to extract standard classifiers from class-conditional
                            diffusion models trained on ImageNet. Even though these diffusion models are trained with
                            weak augmentations and no regularization, we find that they approach the performance of SOTA
                            discriminative ImageNet classifiers. Overall, our strong generalization and robustness
                            results represent an encouraging step toward using generative over discriminative models for
                            downstream tasks.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->


            <!-- Paper video. -->
            <!-- <p style="padding: 20px;" /> -->
            <!-- <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Video</h2>
                    <div class="publication-video">
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/1hYtGZ0CUSA"
                            title="YouTube video player" frameborder="0"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                            allowfullscreen></iframe>
                    </div>
                </div>
            </div> -->
            <!--/ Paper video. -->
        </div>
    </section>

    <p style="padding: 20px;" />

    <!-- Derivation. -->
    <section>
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <h2 class="title is-3">
                        Classification with diffusion models
                    </h2>
                    <div class="content has-text-justified">
                        <p class="equation-text">
                            In general, classification using a conditional generative model can be done by using Bayes'
                            theorem on the model predictions and the prior \(p(\mathbf{c})\) over labels
                            \(\{\mathbf{c}_i\}\):
                        </p>
                        <p class="equation">
                            \begin{equation}
                            p_\theta(\mathbf{c}_i \mid \mathbf{x}) = \frac{p(\mathbf{c}_i)\ p_\theta(\mathbf{x} \mid
                            \mathbf{c}_i)}{\sum_j p(\mathbf{c}_j)\ p_\theta(\mathbf{x} \mid \mathbf{c}_j)}
                            \label{eq:bayes}
                            \end{equation}
                        </p>
                        <p class="equation-text">
                            A uniform prior over \(\{\mathbf{c}_i\}\) (<i>i.e.,</i> \(p(\mathbf{c}_i) = \frac{1}{N}\))
                            is natural and leads to all of the \(p(\mathbf{c})\) terms cancelling. For diffusion models,
                            computing \(\log p_\theta(\mathbf{x}\mid \mathbf{c})\) is intractable, so we approximate it
                            with the ELBO (see paper &sect3.1), from which we have dropped constant and weighting terms:
                        </p>
                        <p class="equation">
                            \begin{align}
                            \text{ELBO} \approx - \mathbb{E}_{t, \epsilon}[\|\epsilon - \epsilon_\theta(\mathbf{x}_t,
                            \mathbf{c}_i)\|^2]
                            \label{eq:elbo}
                            \end{align}
                        </p>
                        <p class="equation-text">
                            We plug the modified ELBO Eq.&nbsp\ref{eq:elbo} into Eq.&nbsp\ref{eq:bayes} to obtain the
                            posterior over
                            \(\{\mathbf{c}_i\}_{i=1}^N\):
                        </p>
                        <p class="equation">
                            \begin{align}
                            p_\theta(\mathbf{c}_i \mid \mathbf{x})
                            &\approx \frac{\exp\{- \mathbb{E}_{t, \epsilon}[\|\epsilon - \epsilon_\theta(\mathbf{x}_t,
                            \mathbf{c}_i)\|^2]\}}{\sum_j \exp\{- \mathbb{E}_{t, \epsilon}[\|\epsilon -
                            \epsilon_\theta(\mathbf{x}_t, \mathbf{c}_j)\|^2]\}}
                            \label{eq:posterior}
                            \end{align}
                        </p>
                        <p class="equation-text">
                            We compute an unbiased Monte Carlo estimate of each expectation by sampling \(N\) \((t_i,
                            \epsilon_i)\) pairs, with \(t_i \sim [1, 1000]\) and \(\epsilon \sim \mathcal{N}(0, I)\),
                            and computing
                        </p>
                        <p class="equation">
                            \begin{align}
                            \frac{1}{N}\sum_{i=1}^N \left\|\epsilon_i - \epsilon_\theta(\sqrt{\bar
                            \alpha_{t_i}}\mathbf{x} + \sqrt{1-\bar\alpha_{t_i}} \epsilon_i, \mathbf{c}_j)\right\|^2
                            \label{eq:monte_carlo}
                            \end{align}
                        </p>
                        <p class="equation-text">
                            By plugging Eq.&nbsp;\ref{eq:monte_carlo} into Eq.&nbsp;\ref{eq:posterior}, we can extract a
                            classifier from <i>any</i> conditional diffusion model.
                            This method, which we call <span class="method-name">Diffusion Classifier</span>, is a
                            <i>powerful, hyperparameter-free approach that leverages pretrained diffusion models for
                                classification without any additional training.</i>
                            Diffusion Classifier can be used to extract a zero-shot
                            classifier from a text-to-image model like <a target="_blank"
                                href="https://github.com/Stability-AI/stablediffusion">Stable Diffusion</a>, to extract
                            a standard
                            classifier from a class-conditional diffusion model like <a target="_blank"
                                href="https://arxiv.org/abs/2212.09748">DiT</a>, and so on.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!--/ Derivation. -->

    <p style="padding: 20px;" />
    <section class="section">
        <!-- Zero Shot. -->
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <h2 class="title is-3">Zero-shot Classification</h2>
                    <div class="content has-text-justified">
                        <p>
                            We build <span class="method-name">Diffusion Classifier</span> on top of
                            <a target="_blank" href="https://github.com/Stability-AI/stablediffusion">Stable
                                Diffusion</a>, a
                            text-to-image latent diffusion model trained on a filtered subset of <a target="_blank"
                                href="https://laion.ai/blog/laion-5b/">LAION-5B</a>.
                            Our zero-shot classification method is
                            competitive with CLIP and significantly outperforms the zero-shot diffusion model baseline
                            that trains a
                            classifier on synthetic SD data. It also generally outperforms the baseline trained on
                            Stable Diffusion
                            features, especially on complex datasets like ImageNet. This is especially impressive since
                            the "SD Features"
                            baseline uses the entire training set to train a classifier.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <p style="padding: 20px;" />
        <div class="is-centered has-text-centered">
            <div class="table-container is-max-desktop">
                <table style="width:100%">
                    <caption>
                        Zero-shot classification performance on a suite of tasks.
                    </caption>
                    <tr>
                        <th></th>
                        <th>Zero-shot?</th>
                        <th>Food</th>
                        <th>CIFAR10</th>
                        <th>FGVC</th>
                        <th>Pets</th>
                        <th>Flowers</th>
                        <th>MNIST</th>
                        <th>STL10</th>
                        <th>ImageNet</th>
                        <th>ObjectNet</th>
                    </tr>
                    <tr>
                        <td colspan="11" style="border-bottom: 1px solid #ddd;"></td>
                    </tr>
                    <tr>
                        <td>Synthetic SD Data</td>
                        <!-- <td>&#10003;</td> -->
                        <td style="color:lime">&#10003;</td>
                        <td>12.6</td>
                        <td>35.3</td>
                        <!-- add spaces to make it render inline -->
                        <td>&nbsp;&nbsp;&nbsp;9.4</td>
                        <td>31.3</td>
                        <td>22.1</td>
                        <td>27.9</td>
                        <td>38.0</td>
                        <td>18.9</td>
                        <td>&nbsp;&nbsp;&nbsp;5.2</td>
                    </tr>
                    <tr>
                        <td>SD Features</td>
                        <td style="color:red">&#10007;</td>
                        <td style="color:lightgray">73.0</td>
                        <td style="color:lightgray"><b>84.0</b></td>
                        <td style="color:lightgray"><b>35.2</b></td>
                        <td style="color:lightgray">75.9</td>
                        <td style="color:lightgray"><b>70.0</b></td>
                        <td style="color:lightgray"><b>98.1</b></td>
                        <td style="color:lightgray">87.2</td>
                        <td style="color:lightgray">56.6</td>
                        <td style="color:lightgray">10.2</td>
                    </tr>
                    <tr>
                        <td><span class="method-name">Diffusion Classifier</span></td>
                        <td style="color:lime">&#10003;</td>
                        <td><b>77.9</b></td>
                        <td>76.3</td>
                        <td>24.3</td>
                        <td><b>85.7</b></td>
                        <td>56.8</td>
                        <td>17.4</td>
                        <td><b>94.2</b></td>
                        <td><b>58.4</b></td>
                        <td><b>38.3</b></td>
                    </tr>
                    <tr>
                        <td colspan="11" style="border-bottom: 1px solid #ddd;"></td>
                    </tr>
                    <tr>
                        <td>CLIP ViT-L/14</td>
                        <td style="color:lime">&#10003;</td>
                        <td>93.1</td>
                        <td>94.5</td>
                        <td>32.7</td>
                        <td>93.7</td>
                        <td>79.3</td>
                        <td>62.6</td>
                        <td>99.5</td>
                        <td>73.5</td>
                        <td>68.5</td>
                    </tr>
                    <tr>
                        <td>OpenCLIP ViT-H/14</td>
                        <td style="color:lime">&#10003;</td>
                        <td>92.7</td>
                        <td>97.3</td>
                        <td>42.3</td>
                        <td>94.6</td>
                        <td>79.9</td>
                        <td>78.2</td>
                        <td>98.3</td>
                        <td>76.8</td>
                        <td>69.2</td>
                    </tr>
                </table>
            </div>
        </div>
        <!--/ Zero Shot. -->
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <h2 class="title is-3">Improved Relational Reasoning Abilities</h2>
                    <div class="content has-text-justified">
                        <p>
                            We compare our zero-shot <span class="method-name">Diffusion Classifier</span> method to
                            CLIP and OpenCLIP on
                            <a href="https://arxiv.org/abs/2204.03162" target="_blank">Winoground</a>,
                            a popular benchmark for evaluating the visuo-linguistic compositional reasoning abilities of
                            vision-language models. This benchmark tests whether models can match captions to the
                            correct images when certain entities are swapped in the
                            captions.
                        </p>
                    </div>
                </div>
            </div>
            <p style="padding: 10px;" />
            <div class="container is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column is-three-fourths">
                        <figure>
                            <img src="./static/images/winoground.jpeg" alt="Winoground examples" id="winoground-image"
                                draggable="false" />
                            <figcaption>
                                Results on selected Winoground image-caption pairs.
                            </figcaption>
                        </figure>
                    </div>
                </div>
            </div>
            <p style="padding: 20px;" />
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <div class="content has-text-justified">
                        <p>
                            <span class="method-name">Diffusion Classifier</span> clearly outperfroms when object swaps
                            are involved (Object and Both below).
                            Since Stable Diffusion uses the same text
                            encoder as OpenCLIP ViT-H/14, this improvement must come from better cross-modal binding of
                            concepts to images. Overall, we find it surprising that Stable Diffusion, trained with only
                            sampling in mind, can be repurposed into such a good classifier and reasoner.
                        </p>
                    </div>
                </div>
            </div>
            <div class="table-container is-max-desktop is-centered">
                <table style="width:70%">
                    <caption>
                        Zero-shot reasoning results on Winoground
                    </caption>
                    <thead>
                        <tr>
                            <th>Model</th>
                            <th>Object</th>
                            <th>Relation</th>
                            <th>Both</th>
                            <th>Average</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td colspan="11" style="border-bottom: 1px solid #ddd;"></td>
                        </tr>
                        <tr>
                            <td>Random Chance</td>
                            <td>25.0</td>
                            <td>25.0</td>
                            <td>25.0</td>
                            <td>25.0</td>
                        </tr>
                        <tr>
                            <td>CLIP ViT-L/14</td>
                            <td>27.0</td>
                            <td>25.8</td>
                            <td>57.7</td>
                            <td>28.2</td>
                        </tr>
                        <tr>
                            <td>OpenCLIP ViT-H/14</td>
                            <td>39.0</td>
                            <td><strong>26.6</strong></td>
                            <td>57.7</td>
                            <td>33.0</td>
                        </tr>
                        <tr>
                            <td><span class="method-name">Diffusion Classifier</span></td>
                            <td><strong>41.8</strong></td>
                            <td>25.3</td>
                            <td><strong>69.2</strong></td>
                            <td><strong>34.0</strong></td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <h2 class="title is-3">Strong Standard Classification Ability</h2>
                    <div class="content has-text-justified">
                        <p>
                            We use <span class="method-name">Diffusion Classifier</span> to obtain a standard 1000-way
                            classifier on ImageNet from a pretrained <a target="_blank"
                                href="https://arxiv.org/abs/2303.16203">Diffusion Transformer</a> (DiT) model. DiT is a
                            class-conditional diffusion model trained solely on ImageNet-1k, with only random horizontal
                            flips and no regularization. We compare Diffusion Classifier in this setting to strong
                            discriminative classifiers like ResNet-50 and ViT-B/16 in the table below.
                            We highlight cells in green where Diffusion Classifier outperforms.
                        </p>
                    </div>
                </div>
            </div>
            <div class="table-container is-max-desktop is-centered">
                <table>
                    <caption>
                        Diffusion Classifier performs well ID and OOD.
                    </caption>
                    <thead>
                        <tr>
                            <th rowspan="2">Method</th>
                            <th colspan="1"  style="text-align: right !important;">ID</th>
                            <th colspan="3" style="text-align: center !important;">OOD</th>
                        </tr>
                        <tr>
                            <th>IN</th>
                            <th>IN-v2</th>
                            <th>IN-A</th>
                            <th>ObjectNet</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td colspan="11" style="border-bottom: 1px solid #ddd;"></td>
                        </tr>
                        <tr>
                            <td>ResNet-18</td>
                            <td class="table-highlight">74.1</td>
                            <td class="table-highlight">57.3</td>
                            <td class="table-highlight">15.0</td>
                            <td class="table-highlight">26.6</td>
                        </tr>
                        <tr>
                            <td>ResNet-34</td>
                            <td class="table-highlight">78.1</td>
                            <td class="table-highlight">59.8</td>
                            <td class="table-highlight">10.5</td>
                            <td class="table-highlight">31.6</td>
                        </tr>
                        <tr>
                            <td>ResNet-50</td>
                            <td>79.7</td>
                            <td class="table-highlight">61.6</td>
                            <td class="table-highlight">9.8</td>
                            <td>35.6</td>
                        </tr>
                        <tr>
                            <td>ResNet-101</td>
                            <td>82.2</td>
                            <td>63.2</td>
                            <td class="table-highlight">19.5</td>
                            <td>38.2</td>
                        </tr>
                        <tr>
                            <td>ViT-L/32</td>
                            <td>79.0</td>
                            <td class="table-highlight">61.6</td>
                            <td>26.3</td>
                            <td class="table-highlight">29.9</td>
                        </tr>
                        <tr>
                            <td>ViT-L/16</td>
                            <td>81.0</td>
                            <td>66.6</td>
                            <td>25.6</td>
                            <td>36.7</td>
                        </tr>
                        <tr>
                            <td>ViT-B/16</td>
                            <td>83.4</td>
                            <td>66.6</td>
                            <td>30.1</td>
                            <td>37.8</td>
                        </tr>
                        <tr>
                            <td><span class="method-name">Diffusion Classifier</span></td>
                            <td>78.9</td>
                            <td>62.1</td>
                            <td>22.6</td>
                            <td>32.3</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <div class="content has-text-justified">
                        <p>
                            Despite the fact that the discriminative models are trained with highly tuned learning rate
                            schedulers, augmentation strategies, and regularizers, Diffusion Classifier outperforms
                            many of them on ImageNet, both in-distribution and out-of-distribution.
                            <strong>To the best of our knowledge, our approach is among the first generative modeling approaches to be competitive with SOTA discriminative classifiers on ImageNet.</strong>
                        </p>
                    </div>
                </div>
            </div>
        </div>
        </div>
    </section>

    <section class="section" id="paper">
        <div class="container is-mobile">
            <div class="columns is-centered has-text-centered">
                <div class="container content">
                    <h2 class="title is-3">BibTeX</h2>
                    <div id="bibtex" class="column has-text-justified is-centered">
                        <!-- https://github.com/SaswatPadhi/prismjs-bibtex -->
                        <pre><code class="language-bibtex">@misc{li2023diffusion,
    title={Your Diffusion Model is Secretly a Zero-Shot Classifier}, 
    author={Alexander C. Li and Mihir Prabhudesai and Shivam Duggal and Ellis Brown and Deepak Pathak},
    year={2023},
    eprint={2303.16203},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}</code></pre>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <!-- TODO: UPDATE -->
                <a class="icon-link" href="https://arxiv.org/abs/2303.16203" target="_blank">
                    <i class="ai ai-arxiv"></i>
                </a>
                &nbsp;
                <!-- TODO: UPDATE -->
                <a class="icon-link" href="./static/docs/DiffusionClassifier.pdf" target="_blank">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <!-- &nbsp;
                <a class="icon-link" href="https://youtu.be/1hYtGZ0CUSA" target="_blank">
                    <i class="fab fa-youtube"></i>
                </a> -->
                <!-- &nbsp;
                <a class="icon-link" href="./static/docs/InternetExplorer.pptx" target="_blank">
                    <i class="fas fa-file-powerpoint"></i>
                </a> -->
                &nbsp;
                <a class="icon-link" href="https://github.com/diffusion-classifier/diffusion-classifier"
                    target="_blank">
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="content">
                    <p>
                        Page source code was adapted from
                        <a href="https://nerfies.github.io" target="_blank">here</a>
                        and
                        <a href="https://internet-explorer-ssl.github.io"
                            target="_blank">here</a>,
                        and can be found in <a
                            href="https://github.com/diffusion-classifier/diffusion-classifier.github.io"
                            target="_blank">this repository</a>.
                    </p>
                </div>
            </div>
    </footer>

    <script src="./static/js/index.js"></script>
    <script src="./static/js/prism.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.0.1/prism-bibtex.js"
        integrity="sha256-+dK6uqUp/DnP6ef97s8XcoynBnGe5vM5gvBECH0EB3U=" crossorigin="anonymous">
        </script>
</body>

</html>